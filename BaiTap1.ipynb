{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HienNguyenMinh/PythonAssignment/blob/main/BaiTap1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Học viên: Nguyễn Thị Minh Hiền\n",
        "\n",
        "Khóa: MSE11_HCM\n",
        "\n",
        "\n",
        "#Giải Thích Để Hiểu Về M5-Forecasting Bằng Tiếng Việt\n",
        "#Giới thiệu:\n",
        "Trong cuộc thi tên là M5-Forecasting, những người tham gia cuộc thi sử dụng dữ liệu bán hàng phân cấp được trích xuất từ Walmart cho việc phân tích và dự đoán doanh số hàng ngày trong 28 ngày tới. *(Walmart là công ty lớn nhất thế giới theo doanh thu)*.\n",
        "Tập dữ liệu bán hàng chứa thông tin của khoảng 30.000 mặt hàng khác nhau trong gần 1900 ngày. Dữ liệu được phân bổ quanh các cửa hàng ở ba tiêu bang Hoa Kỳ (California, Texa và Wisconsin) bao gồm các cấp mặt hàng, bộ phận, danh mục sản phẩm và cấp chi tiết cửa hàng. Ngoài ra, tập dữ liệu cũng có các biến số giải thích về giá cả, các chương trình khuyến mãi, ngày trong tuần và các sự kiện đặc biệt. Hơn nữa, tập dữ liệu mạnh mẽ này không chỉ giúp cải thiện độ chính xác của dự báo, mà còn giúp hiển thị các mô hình bán hàng cơ bản thông qua các ngôn ngữ khác nhau cũng như dựa trên các danh mục sản phẩm khác nhau cung cấp giá trị cho các tầm nhìn kinh doanh.\n",
        "\n",
        "Theo thực tế là một tập dữ liệu lớn được tạo sẵn, chúng ta bắt đầu với một công thức kinh doanh được đưa ra xoay quanh vài vấn đề. Liệu tập dữ liệu này có đủ để trả lời các câu hỏi đó hay không. Nếu câu trả lời chưa được tìm thấy từ tập dữ liệu này, thì ít nhất các thông tin cần thiết theo tập điểm dữ liệu cũng giúp cải thiện việc thiết kế dữ liệu trong tương lai. \n",
        "\n",
        "#Báo cáo vấn đề\n",
        "Một tập dữ liệu lớn khiến cho việc tìm kiếm tất cả các mẫu cơ bản trong tập dữ liệu đó trở nên khó khăn. May mắn thay, việc đặt ra các hỏi có tính chất SMART rất hữu ích với việc hiểu các mẫu mà có thể vô tình không nhìn thấy nó trong lần đầu tiếp cận vào tập dữ liệu. *(SMART: cụ thể, có thể đo lường, có thể đạt được, có liên quan và có giới hạn thời gian)*.\n",
        "\n",
        "Trong các vấn đề cụ thể của m5-forecasting đặc biệt quan tâm việc tìm ra câu trả lời cho các câu hỏi sau:\n",
        "\n",
        "* Sự phân phối chung của các ID mặt hàng trên các danh mục là gì?\n",
        "* Hành vi của các danh mục trên các cửa hàng khác nhau là gì?\n",
        "* ID của mặt hàng bán chạy nhất?\n",
        "* ID của mặt hàng trong mỗi danh mục có nhiều doanh thu nhất?\n",
        "* Doanh thu bán hàng thu được nhiều nhất là bao nhiêu? Nó có phải là ID của các mặt hàng bán chạy nhất, mang lại doanh thu cao nhất, hoặc có thay đổi theo xu hướng không?\n",
        "* Hành vi của tổng doanh số bán hàng là gì?\n",
        "* Hành vi của ID các mặt hàng đang bán trong các ngày khác nhau trong tuần là gì? Có ngày cụ thể nào mà hôm đó có doanh thu cao nhất? Xu hướng thay đổi như thế nào ở các cửa hàng khác nhau?\n",
        "\n",
        "Và cuối cùng, chúng tôi sẽ sử dụng SARIMAX và Facebook đã phát triển mô hình Prophet để dự báo doanh số bán hàng trong 28 ngày tới.\n",
        "\n",
        "#Các chỉ số đánh giá:\n",
        "Để đưa ra dự báo một chuổi thời gian (time series), chung ta dùng các error metrics sau:\n",
        "1. RMSE (Root Mean Square Error): Để đánh giá dự báo bán hàng được thực hiện bằng SARIMAX, RMSE error metric được sử dụng. Chuỗi thời gian được sử dụng trong trường hợp này, lấy số lượng bán hàng trung bình được thực hiện, trong suốt gần 1900 ngày, bỏ qua việc sắp xếp dữ liệu thứ cấp ban đầu của id sản phẩm cùng với một số cấp độ khác. Mức độ tối đa của error metric RMSE không bị vô hiệu vì chúng tôi đang xem xét số lượng bán hàng trung bình được thực hiện, do đó tận dụng hiệu quả của rất nhiều số 0 đối với nhiều id sản phẩm, bên cạnh số ngày.\n",
        "2. Custom Loss (WMAPE): error metric này được sử dụng cho những trường hợp mà mức độ ưu tiên của ID sản phẩm được xem xét cùng với doanh số đã thực hiện. Các trọng số được tính toán bằng cách chia sự khác biệt giữa dự báo và giá trị bán hàng thực tế cho giá trị trung bình của chúng.\n",
        "3. WRMSSE (Weighted Root Mean Square Scaled Error): WRMSSE được tính khi khung dữ liệu sẵn sàng dự đoán (dự báo gần 30.000 id sản phẩm) đã sẵn sàng. Việc tính toán WRMSSE yêu cầu phải sử dụng tổng số mục nhập của tất cả id sản phẩm (gần 30.000 sản phẩm) và sau đó là sự khác biệt giữa các giá trị của tập dữ liệu xác thực, tức là sales_train_validation.csv và khung dữ liệu được dự báo. WRMSSE eror metirc này là chỉ số do cuộc thi cung cấp và đã được tối ưu hóa để sử dụng cho cuộc thi hiện tại. Để đánh giá nó, chúng tôi sẽ phải sử dụng toàn bộ tập dữ liệu của sales_train_validation.csv đã được cung cấp trong một tệp csv.\n"
      ],
      "metadata": {
        "id": "VM0XZcspKJn1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tải các thư viện cần dùng: \n",
        "\n",
        "* Tải các module như numpy, pandas, pyplot, time, math, datetime, widgets..Dùng dòng lệnh: <font color='blue'> import <tên module> </font> hoặc <font color='blue'>import <tên module> as <định danh></font>\n",
        "\n",
        "* Tải các hàm như display, KDTree...Dùng dòng lệnh: <font color='blue'>from <tên module> import <tên hàm></font>"
      ],
      "metadata": {
        "id": "yOkScJOZQo_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "import math\n",
        "import datetime\n",
        "\n",
        "\n",
        "# Import widgets\n",
        "from ipywidgets import widgets, interactive, interact\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "from math import log, floor\n",
        "from sklearn.neighbors import KDTree\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import plotly.figure_factory as ff\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "import pywt\n",
        "from statsmodels.robust import mad\n",
        "\n",
        "import scipy\n",
        "import statsmodels\n",
        "from scipy import signal\n",
        "\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "import itertools\n",
        "from itertools import cycle\n",
        "plt.style.use('seaborn')\n",
        "color_cycle = cycle(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n"
      ],
      "metadata": {
        "id": "Ua54I91BDqnA"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tải các file dữ liệu dùng cho việc phân tích và dự báo về google Colab bằng cách clone các file này từ một reponsitory trên GitHub:"
      ],
      "metadata": {
        "id": "iRa7Uzie34sG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\n",
        "!sudo apt-get install git-lfs\n",
        "!git lfs install\n",
        "!git clone https://github.com/HienNguyenMinh/PythonAssignment.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5HhxOGoy_eV",
        "outputId": "b249d2e2-a196-4570-ff79-e94f851fdb14"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected operating system as Ubuntu/bionic.\n",
            "Checking for curl...\n",
            "Detected curl...\n",
            "Checking for gpg...\n",
            "Detected gpg...\n",
            "Detected apt version as 1.6.14\n",
            "Running apt-get update... done.\n",
            "Installing apt-transport-https... done.\n",
            "Installing /etc/apt/sources.list.d/github_git-lfs.list...done.\n",
            "Importing packagecloud gpg key... Packagecloud gpg key imported to /etc/apt/keyrings/github_git-lfs-archive-keyring.gpg\n",
            "done.\n",
            "Running apt-get update... done.\n",
            "\n",
            "The repository is setup! You can now install packages.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following packages will be upgraded:\n",
            "  git-lfs\n",
            "1 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n",
            "Need to get 7,168 kB of archives.\n",
            "After this operation, 7,962 kB of additional disk space will be used.\n",
            "Get:1 https://packagecloud.io/github/git-lfs/ubuntu bionic/main amd64 git-lfs amd64 3.2.0 [7,168 kB]\n",
            "Fetched 7,168 kB in 1s (8,537 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "(Reading database ... 123945 files and directories currently installed.)\n",
            "Preparing to unpack .../git-lfs_3.2.0_amd64.deb ...\n",
            "Unpacking git-lfs (3.2.0) over (2.3.4-1) ...\n",
            "Setting up git-lfs (3.2.0) ...\n",
            "Git LFS initialized.\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Git LFS initialized.\n",
            "Cloning into 'PythonAssignment'...\n",
            "remote: Enumerating objects: 43, done.\u001b[K\n",
            "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 43 (delta 8), reused 19 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (43/43), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/PythonAssignment"
      ],
      "metadata": {
        "id": "pPfHU3qFS99y"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kiểm tra các file dữ liệu *.csv được tải về Colab thông qua việc duyệt cây thư mục vừa được tải về Colab và in ra đường dẫn các file dữ liệu: "
      ],
      "metadata": {
        "id": "j4e7kGx347nG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for dirname, _, filenames in os.walk('/content/PythonAssignment/DataSet'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEixpPXw0i21",
        "outputId": "2455fdc6-2d34-4023-a1a2-d923cdc4ea6f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PythonAssignment/DataSet/sales_train_evaluation.csv\n",
            "/content/PythonAssignment/DataSet/calendar.csv\n",
            "/content/PythonAssignment/DataSet/sell_prices.csv\n",
            "/content/PythonAssignment/DataSet/sales_train_validation.csv\n",
            "/content/PythonAssignment/DataSet/sample_submission.csv\n",
            "/content/PythonAssignment/DataSet/.gitattributes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mô tả tập dữ liệu:\n",
        "\n",
        "Các file data được tải vào notebook này như sau:\n",
        "\n",
        "* calendar_df.csv - chứa các thông tin về những ngày mà sản phẩm được bán, thông tin về những ngày lễ và các dịp đặc biệt.\n",
        "* train_sales_df.csv - Chứa dữ liệu lịch sử bán hàng hàng ngày cho mỗi sản phẩm và cửa hàng và ID bộ phận với gần như dữ liệu bán hàng trong 1900 ngày [d_1 - d_1913]\n",
        "* submission_file.csv - Định dạng đúng cho tệp gửi, chứa id sản phẩm và id cột cho dự báo dữ liệu bán hàng 28 ngày tới.\n",
        "* sell_prices_df.csv - chứa thông tin về giá của mỗi sản phẩm đã bán ở mỗi cửa hàng và ngày.\n",
        "* sales_train_evaluation.csv - bao gồm các nhãn hàng [d_1 - d_1941] "
      ],
      "metadata": {
        "id": "dFOaFXSnDTd2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Đọc dữ liệu từ các file *.csv bằng hàm read_csv() của pandas:"
      ],
      "metadata": {
        "id": "PC5JGxEWUEJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sell_prices_df = pd.read_csv('/content/PythonAssignment/DataSet/sell_prices.csv')\n",
        "train_sales_df = pd.read_csv('/content/PythonAssignment/DataSet/sales_train_validation.csv')\n",
        "calendar_df = pd.read_csv('/content/PythonAssignment/DataSet/calendar.csv')\n",
        "submission_file = pd.read_csv('/content/PythonAssignment/DataSet/sample_submission.csv')"
      ],
      "metadata": {
        "id": "tj_pZirOTcMV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In full summary của dataframe để hiểu tập dữ liệu:"
      ],
      "metadata": {
        "id": "iO7-VoUTOMHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sell_prices_df.info()"
      ],
      "metadata": {
        "id": "X6wSE6GqOdZH",
        "outputId": "ced0f171-12d6-41e0-d5d3-2787ccc6ee9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2 entries, 0 to 1\n",
            "Data columns (total 1 columns):\n",
            " #   Column                                      Non-Null Count  Dtype \n",
            "---  ------                                      --------------  ----- \n",
            " 0   version https://git-lfs.github.com/spec/v1  2 non-null      object\n",
            "dtypes: object(1)\n",
            "memory usage: 144.0+ bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sales_df.info()"
      ],
      "metadata": {
        "id": "4cJc4SplO4T_",
        "outputId": "abdd2887-687e-4899-ce7a-eac21a983fc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2 entries, 0 to 1\n",
            "Data columns (total 1 columns):\n",
            " #   Column                                      Non-Null Count  Dtype \n",
            "---  ------                                      --------------  ----- \n",
            " 0   version https://git-lfs.github.com/spec/v1  2 non-null      object\n",
            "dtypes: object(1)\n",
            "memory usage: 144.0+ bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calendar_df.info()"
      ],
      "metadata": {
        "id": "EGDPkvmJO7G3",
        "outputId": "47d939d4-c69d-4210-999b-1bcecaa103b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1969 entries, 0 to 1968\n",
            "Data columns (total 14 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   date          1969 non-null   object\n",
            " 1   wm_yr_wk      1969 non-null   int64 \n",
            " 2   weekday       1969 non-null   object\n",
            " 3   wday          1969 non-null   int64 \n",
            " 4   month         1969 non-null   int64 \n",
            " 5   year          1969 non-null   int64 \n",
            " 6   d             1969 non-null   object\n",
            " 7   event_name_1  162 non-null    object\n",
            " 8   event_type_1  162 non-null    object\n",
            " 9   event_name_2  5 non-null      object\n",
            " 10  event_type_2  5 non-null      object\n",
            " 11  snap_CA       1969 non-null   int64 \n",
            " 12  snap_TX       1969 non-null   int64 \n",
            " 13  snap_WI       1969 non-null   int64 \n",
            "dtypes: int64(7), object(7)\n",
            "memory usage: 215.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3SMpvWVROwsP"
      }
    }
  ]
}