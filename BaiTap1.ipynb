{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HienNguyenMinh/PythonAssignment/blob/main/BaiTap1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Giải Thích Để Hiểu Về M5-Forecasting Bằng Tiếng Việt\n",
        "#Giới thiệu:\n",
        "Trong cuộc thi tên là M5-Forecasting, những người tham gia cuộc thi sử dụng dữ liệu bán hàng phân cấp được trích xuất từ Walmart cho việc phân tích và dự đoán doanh số hàng ngày trong 28 ngày tới. *(Walmart là công ty lớn nhất thế giới theo doanh thu)*.\n",
        "Tập dữ liệu bán hàng chứa thông tin của khoảng 30.000 mặt hàng khác nhau trong gần 1900 ngày. Dữ liệu được phân bổ quanh các cửa hàng ở ba tiêu bang Hoa Kỳ (California, Texa và Wisconsin) bao gồm các cấp mặt hàng, bộ phận, danh mục sản phẩm và cấp chi tiết cửa hàng. Ngoài ra, tập dữ liệu cũng có các biến số giải thích về giá cả, các chương trình khuyến mãi, ngày trong tuần và các sự kiện đặc biệt. Hơn nữa, tập dữ liệu mạnh mẽ này không chỉ giúp cải thiện độ chính xác của dự báo, mà còn giúp hiển thị các mô hình bán hàng cơ bản thông qua các ngôn ngữ khác nhau cũng như dựa trên các danh mục sản phẩm khác nhau cung cấp giá trị cho các tầm nhìn kinh doanh.\n",
        "\n",
        "Theo thực tế là một tập dữ liệu lớn được tạo sẵn, chúng ta bắt đầu với một công thức kinh doanh được đưa ra xoay quanh vài vấn đề. Liệu tập dữ liệu này có đủ để trả lời các câu hỏi đó hay không. Nếu câu trả lời chưa được tìm thấy từ tập dữ liệu này, thì ít nhất các thông tin cần thiết theo tập điểm dữ liệu cũng giúp cải thiện việc thiết kế dữ liệu trong tương lai. \n",
        "\n",
        "#Báo cáo vấn đề\n",
        "Một tập dữ liệu lớn khiến cho việc tìm kiếm tất cả các mẫu cơ bản trong tập dữ liệu đó trở nên khó khăn. May mắn thay, việc đặt ra các hỏi có tính chất SMART rất hữu ích với việc hiểu các mẫu mà có thể vô tình không nhìn thấy nó trong lần đầu tiếp cận vào tập dữ liệu. *(SMART: cụ thể, có thể đo lường, có thể đạt được, có liên quan và có giới hạn thời gian)*.\n",
        "\n",
        "Trong các vấn đề cụ thể của m5-forecasting đặc biệt quan tâm việc tìm ra câu trả lời cho các câu hỏi sau:\n",
        "\n",
        "* Sự phân phối chung của các ID mặt hàng trên các danh mục là gì?\n",
        "* Hành vi của các danh mục trên các cửa hàng khác nhau là gì?\n",
        "* ID của mặt hàng bán chạy nhất?\n",
        "* ID của mặt hàng trong mỗi danh mục có nhiều doanh thu nhất?\n",
        "* Doanh thu bán hàng thu được nhiều nhất là bao nhiêu? Nó có phải là ID của các mặt hàng bán chạy nhất, mang lại doanh thu cao nhất, hoặc có thay đổi theo xu hướng không?\n",
        "* Hành vi của tổng doanh số bán hàng là gì?\n",
        "* Hành vi của ID các mặt hàng đang bán trong các ngày khác nhau trong tuần là gì? Có ngày cụ thể nào mà hôm đó có doanh thu cao nhất? Xu hướng thay đổi như thế nào ở các cửa hàng khác nhau?\n",
        "\n",
        "Và cuối cùng, chúng tôi sẽ sử dụng SARIMAX và Facebook đã phát triển mô hình Prophet để dự báo doanh số bán hàng trong 28 ngày tới.\n",
        "\n",
        "#Các chỉ số đánh giá:\n",
        "Để đưa ra dự báo một chuổi thời gian (time series), chung ta dùng các error metrics sau:\n",
        "1. RMSE (Root Mean Square Error): Để đánh giá dự báo bán hàng được thực hiện bằng SARIMAX, RMSE error metric được sử dụng. Chuỗi thời gian được sử dụng trong trường hợp này, lấy số lượng bán hàng trung bình được thực hiện, trong suốt gần 1900 ngày, bỏ qua việc sắp xếp dữ liệu thứ cấp ban đầu của id sản phẩm cùng với một số cấp độ khác. Mức độ tối đa của error metric RMSE không bị vô hiệu vì chúng tôi đang xem xét số lượng bán hàng trung bình được thực hiện, do đó tận dụng hiệu quả của rất nhiều số 0 đối với nhiều id sản phẩm, bên cạnh số ngày.\n",
        "2. Custom Loss (WMAPE): error metric này được sử dụng cho những trường hợp mà mức độ ưu tiên của ID sản phẩm được xem xét cùng với doanh số đã thực hiện. Các trọng số được tính toán bằng cách chia sự khác biệt giữa dự báo và giá trị bán hàng thực tế cho giá trị trung bình của chúng.\n",
        "3. WRMSSE (Weighted Root Mean Square Scaled Error): WRMSSE được tính khi khung dữ liệu sẵn sàng dự đoán (dự báo gần 30.000 id sản phẩm) đã sẵn sàng. Việc tính toán WRMSSE yêu cầu phải sử dụng tổng số mục nhập của tất cả id sản phẩm (gần 30.000 sản phẩm) và sau đó là sự khác biệt giữa các giá trị của tập dữ liệu xác thực, tức là sales_train_validation.csv và khung dữ liệu được dự báo. WRMSSE eror metirc này là chỉ số do cuộc thi cung cấp và đã được tối ưu hóa để sử dụng cho cuộc thi hiện tại. Để đánh giá nó, chúng tôi sẽ phải sử dụng toàn bộ tập dữ liệu của sales_train_validation.csv đã được cung cấp trong một tệp csv.\n"
      ],
      "metadata": {
        "id": "VM0XZcspKJn1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tải các thư viện cần dùng: \n",
        "\n",
        "* Tải các module như numpy, pandas, pyplot, time, math, datetime, widgets..Dùng dòng lệnh: <font color='blue'> import <tên module> </font> hoặc <font color='blue'>import <tên module> as <định danh></font>\n",
        "\n",
        "* Tải các hàm như display, KDTree...Dùng dòng lệnh: <font color='blue'>from <tên module> import <tên hàm></font>"
      ],
      "metadata": {
        "id": "yOkScJOZQo_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "import math\n",
        "import datetime\n",
        "\n",
        "\n",
        "# Import widgets\n",
        "from ipywidgets import widgets, interactive, interact\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "from math import log, floor\n",
        "from sklearn.neighbors import KDTree\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import plotly.figure_factory as ff\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "import pywt\n",
        "from statsmodels.robust import mad\n",
        "\n",
        "import scipy\n",
        "import statsmodels\n",
        "from scipy import signal\n",
        "\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "import itertools\n",
        "from itertools import cycle\n",
        "plt.style.use('seaborn')\n",
        "color_cycle = cycle(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n"
      ],
      "metadata": {
        "id": "Ua54I91BDqnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/HienNguyenMinh/PythonAssignment.git\n",
        "\n",
        "from google.colab import files\n"
      ],
      "metadata": {
        "id": "H5HhxOGoy_eV",
        "outputId": "6e51835c-3cd1-4265-d24b-c2f48d11947d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PythonAssignment'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 34 (delta 5), reused 19 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (34/34), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for dirname, _, filenames in os.walk('/content/PythonAssignment/DataSet'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "id": "CEixpPXw0i21",
        "outputId": "52dcc518-b6ec-432f-b505-51b8899bf349",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PythonAssignment/DataSet/sales_train_evaluation.csv\n",
            "/content/PythonAssignment/DataSet/calendar.csv\n",
            "/content/PythonAssignment/DataSet/sell_prices.csv\n",
            "/content/PythonAssignment/DataSet/sales_train_validation.csv\n",
            "/content/PythonAssignment/DataSet/sample_submission.csv\n",
            "/content/PythonAssignment/DataSet/.gitattributes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%rm -rf /content/PythonAssignment"
      ],
      "metadata": {
        "id": "Ma70pkvXyMy8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PC5JGxEWUEJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sell_prices_df = pd.read_csv('/dataset/sell_prices.csv')\n",
        "train_sales_df = pd.read_csv('/dataset/sales_train_validation.csv')\n",
        "calendar_df = pd.read_csv('/dataset/calendar.csv')\n",
        "submission_file = pd.read_csv('/dataset/sample_submission.csv')"
      ],
      "metadata": {
        "id": "tj_pZirOTcMV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}